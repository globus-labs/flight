{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed FLoX using ProxyStore and Globus Compute on CHI@Edge\n",
    "\n",
    "This notebook details how to set up Globus Compute/ProxyStore/CHI@Edge containers for distributed FLoX\n",
    "\n",
    "## Globus Auth\n",
    "To automate the process of launching CHI@Edge containers without manually authenticating with Globus auth, we rely on a Docker image set up to use\n",
    "Globus Auth ID/Secret tokens. In order to obtain these tokens, from the [Globus web app](https://app.globus.org) you can access Settings > Developers > Advanced Registration and fill out the form. Once completed, the tokens will be generated and provided to you. For this notebook to work, it is recommended to set environment variables `GLOBUS_CLIENT_ID` and `GLOBUS_CLIENT_SECRET` with their corresponding values.\n",
    "\n",
    "## CHI@Edge auth\n",
    "CHI@Edge provide instruction ([found here](https://chameleoncloud.readthedocs.io/en/latest/technical/cli.html#cli-authentication)) for how to authenticate with CHI and use the CLI and APIs locally. All these instructions must be followed and the OpenStack RC script must be sourced prior to executing this notebook.\n",
    "\n",
    "## Notebook dependencies\n",
    "This notebook makes use of both FLoX and Chi@Edge dependencies. It is necessary to pip install the `distributed` branch of FLoX and install python-chi-edge. Futhermore `proxystore[endpoints]` and `globus-compute-endpoint` need to also be pip installed and configured prior to notebook execution. The constant variables `LEADER_PS_UUID` and `LEADER_GC_UUID` in the cell below must be update with these local endpoint values.\n",
    "\n",
    "## Troubleshooting\n",
    "Make sure python (major) versions are consistent between all devices. For instance, the docker image used by the CHI@Edge devices use Python3.10. In addition, urllib3 installed in the Docker image is 2.0.7, whereas locally it might be below 2.0.0 . This has been found to be a source of error.\n",
    "\n",
    "In general CHI@Edge containers might be flaky to deploy. Rerun the cells where the container is created if the container creating failed without any real reason.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# environment variables\n",
    "GLOBUS_CLIENT_ID=os.environ.get('GLOBUS_CLIENT_ID')\n",
    "GLOBUS_CLIENT_SECRET=os.environ.get('GLOBUS_CLIENT_SECRET')\n",
    "\n",
    "CHI_PROJ_NAME='CHI-231082' # Change to your project name\n",
    "LEASE_DURATION=2 # Change if you need more/less\n",
    "N_DEVICES=2 # Change if you need more/less\n",
    "\n",
    "DOCKER_IMAGE='valhayot/flox-images:latest'\n",
    "\n",
    "CONTAINER_ENV = {\n",
    "    'FUNCX_SDK_CLIENT_ID': GLOBUS_CLIENT_ID,\n",
    "    'FUNCX_SDK_CLIENT_SECRET': GLOBUS_CLIENT_SECRET,\n",
    "    'PROXYSTORE_GLOBUS_CLIENT_ID': GLOBUS_CLIENT_ID,\n",
    "    'PROXYSTORE_GLOBUS_CLIENT_SECRET': GLOBUS_CLIENT_SECRET,\n",
    "}\n",
    "\n",
    "CONTAINER_PORTS=[5671, 8675]\n",
    "\n",
    "USERNAME = os.environ.get('USER')\n",
    "MACHINE_NAME = 'raspberrypi4-64'\n",
    "\n",
    "RESERVATION: str | None = None # if a reservation id is provided, it will not try to create a new reservation\n",
    "\n",
    "LEADER_PS_UUID = 'b72af0a0-1030-4720-9ce7-3b975f34107f' # update with local proxystore endpoint uuid\n",
    "LEADER_GC_UUID = '470973b0-815d-4be2-a651-f0239e05dc2b' # update with local globus-compute endpoint uuid\n",
    "\n",
    "# set environment vars for notebook\n",
    "os.environ['FUNCX_SDK_CLIENT_ID'] = GLOBUS_CLIENT_ID\n",
    "os.environ['FUNCX_SDK_CLIENT_SECRET'] = GLOBUS_CLIENT_SECRET\n",
    "os.environ['PROXYSTORE_GLOBUS_CLIENT_ID'] = GLOBUS_CLIENT_ID\n",
    "os.environ['PROXYSTORE_GLOBUS_CLIENT_SECRET'] = GLOBUS_CLIENT_SECRET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now using CHI@Edge:\n",
      "URL: https://chi.edge.chameleoncloud.org\n",
      "Location: University of Chicago, Chicago, Illinois, USA\n",
      "Support contact: help@chameleoncloud.org\n"
     ]
    }
   ],
   "source": [
    "import chi\n",
    "# Before we go any further, we need to select which Chameleon site we will be using.\n",
    "chi.set('project_domain_name', 'chameleon')\n",
    "chi.set('project_name', CHI_PROJ_NAME)\n",
    "chi.use_site(\"CHI@Edge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for creating reservations and containers\n",
    "\n",
    "from chi import container\n",
    "from chi import lease\n",
    "\n",
    "\n",
    "def create_reservation(username, machine_name, lease_duration=1, n_devices=1):\n",
    "    # get dates for lease start and end\n",
    "    start, end = lease.lease_duration(days=lease_duration)\n",
    "\n",
    "    # make a unique name for the lease\n",
    "    lease_name = f\"{username}-{machine_name}-{start}\"\n",
    "\n",
    "    reservations = []\n",
    "    lease.add_device_reservation(reservations, count=n_devices, machine_name=machine_name)\n",
    "    container_lease = lease.create_lease(lease_name, reservations)\n",
    "    lease_id = container_lease[\"id\"]\n",
    "    reservation_id = lease.get_device_reservation(lease_id)\n",
    "\n",
    "    print(f\"created lease with name {lease_name} and uuid {lease_id} and reservation id {reservation_id}, waiting for it to start. This can take up to 60s.\")\n",
    "    lease.wait_for_active(lease_id)\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return reservation_id\n",
    "\n",
    "def create_container(username, machine_name, reservation_id, docker_image, container_ports, container_env, name_suffix: str | None=None):\n",
    "    print(\"Requesting container ...\")\n",
    "\n",
    "    # set a name for the container. Becaue CHI@Edge uses Kubernetes, ensure that underscores aren't in the name\n",
    "    if name_suffix is not None:\n",
    "        container_name = f\"{username}-{machine_name}-{name_suffix}\".replace(\"_\",\"-\")\n",
    "    else:\n",
    "        container_name = f\"{username}-{machine_name}\".replace(\"_\",\"-\")\n",
    "        \n",
    "\n",
    "    try:\n",
    "        my_container = container.create_container(\n",
    "            container_name, \n",
    "            image=docker_image,\n",
    "            exposed_ports=container_ports,\n",
    "            environment=container_env,\n",
    "            reservation_id=reservation_id,\n",
    "            platform_version=2,\n",
    "        )\n",
    "    except RuntimeError as ex:\n",
    "        print(ex)\n",
    "        print(f\"please stop and/or delete {container_name} and try again\")\n",
    "    else:\n",
    "        print(f\"Successfully created container: {container_name}!\")\n",
    "    \n",
    "    return my_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reservation\n",
    "if RESERVATION is None:\n",
    "    RESERVATION = create_reservation(USERNAME, MACHINE_NAME, lease_duration=LEASE_DURATION, N_DEVICES=N_DEVICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting container ...\n",
      "Successfully created container: valeriehayot-sasson-raspberrypi4-64-1!\n"
     ]
    }
   ],
   "source": [
    "# create first container\n",
    "worker_1 = create_container(USERNAME, MACHINE_NAME, RESERVATION, DOCKER_IMAGE, CONTAINER_PORTS, CONTAINER_ENV, name_suffix='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting container ...\n",
      "Successfully created container: valeriehayot-sasson-raspberrypi4-64-2!\n"
     ]
    }
   ],
   "source": [
    "# create second container\n",
    "worker_2 = create_container(USERNAME, MACHINE_NAME, RESERVATION, DOCKER_IMAGE, CONTAINER_PORTS, CONTAINER_ENV, name_suffix='2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ps_uuid(worker_uuid, split_idx=-1):\n",
    "    cmd = 'proxystore-endpoint list'\n",
    "    return container.execute(worker_uuid, cmd)[\"output\"].split()[split_idx]\n",
    "\n",
    "def get_gc_uuid(worker_uuid, split_idx=-7):\n",
    "    cmd = 'globus-compute-endpoint list'\n",
    "    return container.execute(worker_uuid, cmd)[\"output\"].split()[split_idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 1 ProxyStore endpoint UUID: 2dea5f0b-39f3-46bb-9d58-df67deb58108\n"
     ]
    }
   ],
   "source": [
    "w1_ps_endpoint = get_ps_uuid(worker_1.uuid)\n",
    "print(f'Worker 1 ProxyStore endpoint UUID: {w1_ps_endpoint}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 1 Globus Compute endpoint UUID: 675de750-cc84-4fa2-9976-ed9738adeba2\n"
     ]
    }
   ],
   "source": [
    "w1_gc_endpoint = get_gc_uuid(worker_uuid=worker_1.uuid)\n",
    "print(f'Worker 1 Globus Compute endpoint UUID: {w1_gc_endpoint}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 2 ProxyStore endpoint UUID: 190691b5-cb9b-461a-99e9-6c75ffed9b82\n"
     ]
    }
   ],
   "source": [
    "w2_ps_endpoint = get_ps_uuid(worker_uuid=worker_2.uuid)\n",
    "print(f'Worker 2 ProxyStore endpoint UUID: {w2_ps_endpoint}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 2 Globus Compute endpoint UUID: 6199ea17-607f-4196-8aa9-18fa64a31e13\n"
     ]
    }
   ],
   "source": [
    "w2_gc_endpoint = get_gc_uuid(worker_uuid=worker_2.uuid)\n",
    "print(f'Worker 2 Globus Compute endpoint UUID: {w2_gc_endpoint}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create flox topology\n",
    "import yaml\n",
    "\n",
    "topo = {\n",
    "    0: {\n",
    "        'kind': 'leader',\n",
    "        'globus_compute_endpoint': LEADER_GC_UUID,\n",
    "        'proxystore_endpoint': LEADER_PS_UUID,\n",
    "        'children': [1,2]\n",
    "    },\n",
    "    1: {\n",
    "        'kind': 'worker',\n",
    "        'globus_compute_endpoint': w1_gc_endpoint,\n",
    "        'proxystore_endpoint': w1_ps_endpoint,\n",
    "        'children': []\n",
    "    },\n",
    "    2: {\n",
    "        'kind': 'worker',\n",
    "        'globus_compute_endpoint': w2_gc_endpoint,\n",
    "        'proxystore_endpoint': w2_ps_endpoint,\n",
    "        'children': []\n",
    "    }\n",
    "}\n",
    "\n",
    "# save to file\n",
    "with open('../examples/flocks/proxy.yaml', 'w+') as f:\n",
    "    yaml.safe_dump(topo, f, default_flow_style=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Distributed FL\n",
    "**Note: start here if CHI@Edge containers and yaml are already configured and just want to execute FLoX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED: <Future at 0x297624220 state=finished returned JobResult>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED: <Future at 0x297625ea0 state=finished returned JobResult>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED: <Future at 0x297624d30 state=finished returned JobResult>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED: <Future at 0x297657a00 state=finished returned JobResult>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "federated_fit::sync: 100%|██████████| 5/5 [06:07<00:00, 73.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED: <Future at 0x2a90f0490 state=finished returned JobResult>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train/loss</th>\n",
       "      <th>train/epoch</th>\n",
       "      <th>train/batch_idx</th>\n",
       "      <th>train/time</th>\n",
       "      <th>node/idx</th>\n",
       "      <th>node/kind</th>\n",
       "      <th>parent/idx</th>\n",
       "      <th>parent/kind</th>\n",
       "      <th>round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.307554</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-11-02 03:55:29.936379</td>\n",
       "      <td>1</td>\n",
       "      <td>worker</td>\n",
       "      <td>0</td>\n",
       "      <td>leader</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.300235</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-02 03:55:30.021001</td>\n",
       "      <td>1</td>\n",
       "      <td>worker</td>\n",
       "      <td>0</td>\n",
       "      <td>leader</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.300128</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-11-02 03:55:30.125430</td>\n",
       "      <td>1</td>\n",
       "      <td>worker</td>\n",
       "      <td>0</td>\n",
       "      <td>leader</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.288718</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-11-02 03:55:30.225741</td>\n",
       "      <td>1</td>\n",
       "      <td>worker</td>\n",
       "      <td>0</td>\n",
       "      <td>leader</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.290709</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-11-02 03:55:30.340433</td>\n",
       "      <td>1</td>\n",
       "      <td>worker</td>\n",
       "      <td>0</td>\n",
       "      <td>leader</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train/loss  train/epoch  train/batch_idx                 train/time  \\\n",
       "0    2.307554            0                0 2023-11-02 03:55:29.936379   \n",
       "1    2.300235            0                1 2023-11-02 03:55:30.021001   \n",
       "2    2.300128            0                2 2023-11-02 03:55:30.125430   \n",
       "3    2.288718            0                3 2023-11-02 03:55:30.225741   \n",
       "4    2.290709            0                4 2023-11-02 03:55:30.340433   \n",
       "\n",
       "   node/idx node/kind  parent/idx parent/kind  round  \n",
       "0         1    worker           0      leader      0  \n",
       "1         1    worker           0      leader      0  \n",
       "2         1    worker           0      leader      0  \n",
       "3         1    worker           0      leader      0  \n",
       "4         1    worker           0      leader      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run flox\n",
    "import os\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from flox.flock import Flock\n",
    "from flox.nn import FloxModule\n",
    "from flox.utils.data import federated_split, fed_barplot\n",
    "from flox.run import federated_fit\n",
    "from flox.strategies.registry.fedavg import FedAvg\n",
    "\n",
    "#import logging\n",
    "\n",
    "#logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "os.environ[\"TORCH_DATASETS\"] = os.getcwd()\n",
    "\n",
    "flock = Flock.from_yaml(\"../examples/flocks/proxy.yaml\")\n",
    "\n",
    "fashion_mnist = FashionMNIST(root=os.getcwd(), download=True, train=False)\n",
    "data = FashionMNIST(root=os.getcwd(), download=True, train=False, transform=ToTensor())\n",
    "federated_data = federated_split(\n",
    "    data,\n",
    "    flock,\n",
    "    10,\n",
    "    samples_alpha=1,\n",
    "    labels_alpha=1\n",
    ")\n",
    "\n",
    "class MyModule(FloxModule):\n",
    "    def __init__(self, lr: float = 0.01):\n",
    "        import torch.nn as nn\n",
    "\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return self.linear_stack(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        import torch.nn as nn\n",
    "        # This callback is added by ``FloxModule`` and based on the ``LightningModule``\n",
    "        inputs, targets = batch\n",
    "        preds = self(inputs)\n",
    "        loss = nn.functional.cross_entropy(preds, targets)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        from torch.optim import SGD\n",
    "        # This callback is added by ``FloxModule`` and based on the ``LightningModule``\n",
    "        return SGD(self.parameters(), lr=self.lr)\n",
    "\n",
    "\n",
    "results: DataFrame = federated_fit(\n",
    "    flock,\n",
    "    MyModule,\n",
    "    federated_data,\n",
    "    num_global_rounds=5,\n",
    "    strategy=\"fedprox\",\n",
    "    where=\"globus_compute\"\n",
    ")\n",
    "results.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
